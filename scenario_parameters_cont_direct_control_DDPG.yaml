action_description:
  action_designation: direct
  action_sigma: 1.645
  action_type: continous
  eps_schedule: 0,0.9;8000,0.2
  max_power: None
  angle_range: -15,15
controller:
  coeffs: 0.1,0.5
  type: pd
learning_algorithm:
  actor_activation: relu
  critic_activation: relu
  batch_size: 8192
  drop_out: 0.0
  gamma: 0.999375 # horizon = 1600 steps
  last_activation: tan_h
  actor_layers: 60,60
  critic_layers: 60,60
  loss: mse
  max_action: 10
  n_batches: 16
  name: DDPG
  target_frequency: 10
  tau: 0.05
logdata: null
movers:
  river_boat_0:
    use_default: True
    modifications:
      fuel_capacity: 0.5
      bsfc: 5.0e-8
    # specify what should be in the state and how to normalize it
    state: 
      delta: num, 0.758375, linear # [rad] pi/4
      dest_dist: num, 300.0, linear # [m]
      mu: num, 6.283185307179586, linear # [rad]
      #power: derived, power_max, linear # [watt]
      psi: num, 6.283185307179586, linear # [rad]
      psi_dot: num, 6.283185307179586, linear # [rad/s]
      v_xp: num, 5.0, linear # [m/s]
      v_yp: num, 5.0, linear # [m/s]
    is_agent: True
optimizer:
  beta_1: 0.9
  beta_2: 0.999
  learn_rate: 0.001
  name: ADAM
replay_data:
  capacity: 100000
  replay_strategy: all_in_one
reward_function:
  angle_in_tolerance_reward: 1.0
  angle_tolerance: 5.0
  close_reward_factor: 1.0
  crash: -100.0
  goal_dst: 5.0
  heading_reward: 0.075
  name: EveryStepForGettingCloserToGoalAndHeading
  success: 100.0
  total_norm_factor: 100.0
#reward_function:
#  goal_dst: 5.0
#  name: InstantSuccessReward
#  success: 1.0
#  crash: -1.0
#  total_norm_factor: 1.0
scenario:
  evaluation_frequency: 100
  continue_learning: false
  domain: 200
  experiment_set: TuneDDPGDirectControlRichReward
  max_time: 150
  name: no_obstacles
  num_episodes: 10001
  seed: 0
  time_step: 0.1
  trial_num: 1
  save_training_telemetry: False
  save_freq: 1

evaluation_init:
  destination_x: 150,150,150,150,150,150,150,150,150,150,150,150,150,150,150,150,150,150,150,150,150,150,150,150
  destination_y: 100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100
  river_boat_0:
    x_pos: 25,25,25,25,25,25,25,25,100,100,100,100,100,100,100,100,140,140,140,140,140,140,140,140
    y_pos: 100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100
    psi: 0,0.785398163,1.570796327,2.35619449,3.141592654,3.926990817,4.71238898,5.497787144,0,0.785398163,1.570796327,2.35619449,3.141592654,3.926990817,4.71238898,5.497787144,0,0.785398163,1.570796327,2.35619449,3.141592654,3.926990817,4.71238898,5.497787144
    psi_dot: 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
    v_xp: 0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5
    v_yp: 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
    delta: 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0